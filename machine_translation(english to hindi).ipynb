{"cells":[{"metadata":{},"cell_type":"markdown","source":"# **Machine Translation Using Attention:**"},{"metadata":{},"cell_type":"markdown","source":"# English to Hindi Translation: "},{"metadata":{},"cell_type":"markdown","source":"## **Data Preparation:**"},{"metadata":{},"cell_type":"markdown","source":"## **Import all libraries:**"},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"import numpy as np \n\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\n\nimport os\nimport tensorflow as tf\n\nimport time\nimport re\nimport string\n\nfrom tqdm import tqdm","execution_count":1,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Preprocessing:"},{"metadata":{"trusted":true},"cell_type":"code","source":"file=open('../input/hindi-english-sentence-pairs/hin.txt')","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ascii = set(string.printable)   \n\ndef seperate_eng_and_hin(s):\n    for i in range(len(s)):\n        if s[i] not in ascii:\n            return s[:i],s[i:]","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"c=0\nenglish_sentences=[]\nhindi_sentences=[]\nfor i in tqdm(file):\n    match = re.search('CC-BY 2.0', i).start() \n    en,hin=seperate_eng_and_hin(i[:match])\n    english_sentences.append(en)\n    hindi_sentences.append(hin)\n    ","execution_count":4,"outputs":[{"output_type":"stream","text":"2774it [00:00, 34801.46it/s]\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"english_sentences[20:30],hindi_sentences[20:30]","execution_count":5,"outputs":[{"output_type":"execute_result","execution_count":5,"data":{"text/plain":"(['Have fun.\\t',\n  'Have fun.\\t',\n  'Have fun.\\t',\n  'I forgot.\\t',\n  'I forgot.\\t',\n  \"I'll pay.\\t\",\n  \"I'm fine.\\t\",\n  \"I'm full.\\t\",\n  \"Let's go!\\t\",\n  'Answer me.\\t'],\n ['मज़े करना।\\t',\n  'मौज करना।\\t',\n  'मज़े करो।\\t',\n  'मैं भूल गया।\\t',\n  'मैं भूल गई।\\t',\n  'मैं पैसे दूंगा।\\t',\n  'मैं ठीक हूँ।\\t',\n  'मेरा पेट भर गया है।\\t',\n  'चलो चलें!\\t',\n  'मुझे जवाब दो।\\t'])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"data=pd.DataFrame()\n\ndata['english_sentence']=english_sentences\ndata['hindi_sentence']=hindi_sentences","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":7,"outputs":[{"output_type":"execute_result","execution_count":7,"data":{"text/plain":"  english_sentence hindi_sentence\n0           Wow!\\t         वाह!\\t\n1          Help!\\t        बचाओ!\\t\n2          Jump.\\t        उछलो.\\t\n3          Jump.\\t        कूदो.\\t\n4          Jump.\\t       छलांग.\\t","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>english_sentence</th>\n      <th>hindi_sentence</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Wow!\\t</td>\n      <td>वाह!\\t</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Help!\\t</td>\n      <td>बचाओ!\\t</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Jump.\\t</td>\n      <td>उछलो.\\t</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Jump.\\t</td>\n      <td>कूदो.\\t</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Jump.\\t</td>\n      <td>छलांग.\\t</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe()","execution_count":8,"outputs":[{"output_type":"execute_result","execution_count":8,"data":{"text/plain":"                   english_sentence           hindi_sentence\ncount                          2774                     2774\nunique                         2572                     2697\ntop     Is your father a teacher?\\t  उसे सब पसंद करते हैं।\\t\nfreq                              9                        4","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>english_sentence</th>\n      <th>hindi_sentence</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>2774</td>\n      <td>2774</td>\n    </tr>\n    <tr>\n      <th>unique</th>\n      <td>2572</td>\n      <td>2697</td>\n    </tr>\n    <tr>\n      <th>top</th>\n      <td>Is your father a teacher?\\t</td>\n      <td>उसे सब पसंद करते हैं।\\t</td>\n    </tr>\n    <tr>\n      <th>freq</th>\n      <td>9</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":9,"outputs":[{"output_type":"stream","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 2774 entries, 0 to 2773\nData columns (total 2 columns):\n #   Column            Non-Null Count  Dtype \n---  ------            --------------  ----- \n 0   english_sentence  2774 non-null   object\n 1   hindi_sentence    2774 non-null   object\ndtypes: object(2)\nmemory usage: 43.5+ KB\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"data=data.dropna()\nprint(data.shape)","execution_count":10,"outputs":[{"output_type":"stream","text":"(2774, 2)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"n=int(input())\n\nen=data['english_sentence'].values[n]\n\nhi=data['hindi_sentence'].values[n]\n\nprint(en)\n\nprint(hi)","execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":"45\nWonderful!\t\nअद्भुत\t\n"}]},{"metadata":{},"cell_type":"markdown","source":"#  Cleaning The Data:"},{"metadata":{"trusted":true},"cell_type":"code","source":"import string\n\nsc = list(set(string.punctuation))","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['english_sentence']=data['english_sentence'].apply(lambda x: x.lower())","execution_count":13,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.columns","execution_count":14,"outputs":[{"output_type":"execute_result","execution_count":14,"data":{"text/plain":"Index(['english_sentence', 'hindi_sentence'], dtype='object')"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#replace /t wit space in every sentence\ndata['english_sentence']=data['english_sentence'].apply(lambda x: x.replace('\\t',' '))\ndata['hindi_sentence']=data['hindi_sentence'].apply(lambda x: x.replace('\\t',' '))","execution_count":15,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def decontracted(phrase):\n    # specific\n    phrase = re.sub(r\"won't\", \"will not\", phrase)\n    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n\n    # general\n    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n    return phrase","execution_count":16,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['english_sentence']=data['english_sentence'].apply(lambda x: decontracted(x))","execution_count":17,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#remove special characters from sentences\ndata['english_sentence']=data['english_sentence'].apply(lambda x: ''.join(ch for ch in x if ch not in sc))\ndata['hindi_sentence']=data['hindi_sentence'].apply(lambda x: ''.join(ch for ch in x if ch not in sc))","execution_count":18,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#remove digits from sentences\ndata['english_sentence']=data['english_sentence'].apply(lambda x: ''.join([i for i in x if not i.isdigit()]))\ndata['hindi_sentence']=data['hindi_sentence'].apply(lambda x: ''.join([i for i in x if not i.isdigit()]))","execution_count":19,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#adding <start> and <end> to sentences\ndata['english_sentence']=data['english_sentence'].apply(lambda x: '<start> '+x+' <end>')\ndata['hindi_sentence']=data['hindi_sentence'].apply(lambda x: '<start> '+x+' <end>')","execution_count":20,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#finding lengths of each sentences\ndata['length_eng_sentence']=data['english_sentence'].apply(lambda x:len(x.split(\" \")))\ndata['length_hin_sentence']=data['hindi_sentence'].apply(lambda x:len(x.split(\" \")))","execution_count":21,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":22,"outputs":[{"output_type":"execute_result","execution_count":22,"data":{"text/plain":"      english_sentence        hindi_sentence  length_eng_sentence  \\\n0   <start> wow  <end>    <start> वाह  <end>                    4   \n1  <start> help  <end>   <start> बचाओ  <end>                    4   \n2  <start> jump  <end>   <start> उछलो  <end>                    4   \n3  <start> jump  <end>   <start> कूदो  <end>                    4   \n4  <start> jump  <end>  <start> छलांग  <end>                    4   \n\n   length_hin_sentence  \n0                    4  \n1                    4  \n2                    4  \n3                    4  \n4                    4  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>english_sentence</th>\n      <th>hindi_sentence</th>\n      <th>length_eng_sentence</th>\n      <th>length_hin_sentence</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>&lt;start&gt; wow  &lt;end&gt;</td>\n      <td>&lt;start&gt; वाह  &lt;end&gt;</td>\n      <td>4</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>&lt;start&gt; help  &lt;end&gt;</td>\n      <td>&lt;start&gt; बचाओ  &lt;end&gt;</td>\n      <td>4</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>&lt;start&gt; jump  &lt;end&gt;</td>\n      <td>&lt;start&gt; उछलो  &lt;end&gt;</td>\n      <td>4</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>&lt;start&gt; jump  &lt;end&gt;</td>\n      <td>&lt;start&gt; कूदो  &lt;end&gt;</td>\n      <td>4</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>&lt;start&gt; jump  &lt;end&gt;</td>\n      <td>&lt;start&gt; छलांग  &lt;end&gt;</td>\n      <td>4</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"# Fliter the values based upon length of sentences:"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.columns","execution_count":23,"outputs":[{"output_type":"execute_result","execution_count":23,"data":{"text/plain":"Index(['english_sentence', 'hindi_sentence', 'length_eng_sentence',\n       'length_hin_sentence'],\n      dtype='object')"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"english_sen_lengths=data['length_eng_sentence'].values\nhindi_sen_lengths=data['length_hin_sentence'].values","execution_count":24,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt \n\nsns.distplot(english_sen_lengths,kde=False)\nplt.xlabel('length od sentences')\nplt.ylabel('count')\nplt.show();","execution_count":25,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(hindi_sen_lengths,kde=False)\nplt.xlabel('length od sentences')\nplt.ylabel('count')\nplt.show();","execution_count":26,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('maximum length of english sentences :'+str(max(english_sen_lengths)))\nprint('maximum length of hindi sentences :' + str(max(hindi_sen_lengths)))","execution_count":27,"outputs":[{"output_type":"stream","text":"maximum length of english sentences :26\nmaximum length of hindi sentences :28\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"data=data[data['length_eng_sentence']<=25]\ndata=data[data['length_hin_sentence']<=25]","execution_count":28,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.shape","execution_count":29,"outputs":[{"output_type":"execute_result","execution_count":29,"data":{"text/plain":"(2773, 4)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"n=int(input())\n\nen=data['english_sentence'].values[n]\n\nhi=data['hindi_sentence'].values[n]\n\nprint(en)\n\nprint(hi)","execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":"45\n<start> wonderful  <end>\n<start> अद्भुत  <end>\n"}]},{"metadata":{},"cell_type":"markdown","source":"# Preprocessing the Data"},{"metadata":{},"cell_type":"markdown","source":"* combine all words\n* sort the words based upon frequency \n* assign the ranks of the words based upon frequency\n* convert the text sentence into list of tokens\n* padding the token's list"},{"metadata":{"trusted":true},"cell_type":"code","source":"from collections import Counter \ndef tokenize(lang):\n    words=[]\n    for i in lang:\n        words.extend(i.split())\n    s=Counter(words)\n    a=list(s.keys())\n    b=list(s.values())\n    ind=np.argsort(np.array(b))\n    word_to_ind={}\n    for i in range(len(ind)):\n        word_to_ind[a[ind[-(i+1)]]]=i+1\n    sequences=[]\n    for i in lang:\n        sen=[]\n        for j in i.split():\n            sen.append(word_to_ind[j])\n        sequences.append(sen)\n    pad_sequences = tf.keras.preprocessing.sequence.pad_sequences(sequences,padding='post',maxlen=25)\n    \n    return word_to_ind,pad_sequences\n    ","execution_count":31,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"en_word_to_ind,en_sequences=tokenize(data['english_sentence'].values)\nhin_word_to_ind,hin_sequences=tokenize(data['hindi_sentence'].values)","execution_count":32,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('english vocabulary size : '+str(len(en_word_to_ind)))\nprint('hindi vocabulary size : '+str(len(hin_word_to_ind)))","execution_count":37,"outputs":[{"output_type":"stream","text":"english vocabulary size : 2296\nhindi vocabulary size : 2965\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"en_sequences.shape,hin_sequences.shape","execution_count":38,"outputs":[{"output_type":"execute_result","execution_count":38,"data":{"text/plain":"((2773, 25), (2773, 25))"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"en_sequences[0].shape","execution_count":39,"outputs":[{"output_type":"execute_result","execution_count":39,"data":{"text/plain":"(25,)"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"# Split The data into train and validation:"},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train, x_val, y_train, y_val = train_test_split(en_sequences,hin_sequences, test_size=0.1)\n\n\nprint(len(x_train), len(y_train), len(x_val), len(y_val))","execution_count":40,"outputs":[{"output_type":"stream","text":"2495 2495 278 278\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# shuffle data and use Data Generators:"},{"metadata":{"trusted":true},"cell_type":"code","source":"BUFFER_SIZE = len(x_train)\nBATCH_SIZE = 64\nsteps_per_epoch = len(x_train)//BATCH_SIZE\nembedding_dim = 256\nunits = 512\nvocab_inp_size = len(en_word_to_ind)+1\nvocab_tar_size = len(hin_word_to_ind)+1\n\ndataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(BUFFER_SIZE)\ndataset = dataset.batch(BATCH_SIZE, drop_remainder=True)","execution_count":41,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Attention MOdel:"},{"metadata":{},"cell_type":"markdown","source":"# Enoder of Attention Model:"},{"metadata":{"trusted":true},"cell_type":"code","source":"class Encoder(tf.keras.Model):\n    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n        super(Encoder, self).__init__()\n        self.batch_sz = batch_sz\n        self.enc_units = enc_units\n        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n        self.gru = tf.keras.layers.GRU(self.enc_units,\n                                   return_sequences=True,\n                                   return_state=True,\n                                   recurrent_initializer='glorot_uniform')\n\n    def call(self, x, hidden):\n        x = self.embedding(x)\n        output, state = self.gru(x, initial_state = hidden)\n        return output, state\n\n    def initialize_hidden_state(self):\n        return tf.zeros((self.batch_sz, self.enc_units))","execution_count":42,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n","execution_count":43,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Attention Layer"},{"metadata":{"trusted":true},"cell_type":"code","source":"class BahdanauAttention(tf.keras.layers.Layer):\n    def __init__(self, units):\n        super(BahdanauAttention, self).__init__()\n        self.W1 = tf.keras.layers.Dense(units)\n        self.W2 = tf.keras.layers.Dense(units)\n        self.V = tf.keras.layers.Dense(1)\n\n    def call(self, query, values):\n\n        query_with_time_axis = tf.expand_dims(query, 1)\n\n        score = self.V(tf.nn.tanh(self.W1(query_with_time_axis) + self.W2(values)))\n\n\n        attention_weights = tf.nn.softmax(score, axis=1)\n\n        context_vector = attention_weights * values\n        context_vector = tf.reduce_sum(context_vector, axis=1)\n\n        return context_vector, attention_weights","execution_count":44,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Decoder of Attention Model:"},{"metadata":{"trusted":true},"cell_type":"code","source":"class Decoder(tf.keras.Model):\n    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n        super(Decoder, self).__init__()\n        self.batch_sz = batch_sz\n        self.dec_units = dec_units\n        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n        self.gru = tf.keras.layers.GRU(self.dec_units,\n                                   return_sequences=True,\n                                   return_state=True,\n                                   recurrent_initializer='glorot_uniform')\n        self.fc = tf.keras.layers.Dense(vocab_size)\n\n        self.attention = BahdanauAttention(self.dec_units)\n\n    def call(self, x, hidden, enc_output):\n        context_vector, attention_weights = self.attention(hidden, enc_output)\n\n        x = self.embedding(x)\n\n        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n\n        output, state = self.gru(x)\n\n        \n        output = tf.reshape(output, (-1, output.shape[2]))\n\n        x = self.fc(output)\n\n        return x, state, attention_weights","execution_count":45,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n","execution_count":46,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Define Optimizer and Loss Function:"},{"metadata":{"trusted":true},"cell_type":"code","source":"optimizer = tf.keras.optimizers.Adam()\nloss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n\ndef loss_function(real, pred):\n    mask = tf.math.logical_not(tf.math.equal(real, 0))\n    loss_ = loss_object(real, pred)\n\n    mask = tf.cast(mask, dtype=loss_.dtype)\n    loss_ *= mask\n\n    return tf.reduce_mean(loss_)","execution_count":47,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Define checkpoint to store the Model:"},{"metadata":{"trusted":true},"cell_type":"code","source":"checkpoint_dir = '/kaggle/working/training_checkpoints'\ncheckpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\ncheckpoint = tf.train.Checkpoint(optimizer=optimizer,\n                                 encoder=encoder,\n                                 decoder=decoder)","execution_count":48,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training the Model:"},{"metadata":{"trusted":true},"cell_type":"code","source":"@tf.function\ndef train_step(inp, targ, enc_hidden):\n    loss = 0\n\n    with tf.GradientTape() as tape:\n        enc_output, enc_hidden = encoder(inp, enc_hidden)\n\n        dec_hidden = enc_hidden\n\n        dec_input = tf.expand_dims([hin_word_to_ind['<start>']] * BATCH_SIZE, 1)\n\n        for t in range(1, targ.shape[1]):\n           \n            predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n\n            loss += loss_function(targ[:, t], predictions)\n\n            dec_input = tf.expand_dims(targ[:, t], 1)\n\n    batch_loss = (loss / int(targ.shape[1]))\n\n    variables = encoder.trainable_variables + decoder.trainable_variables\n\n    gradients = tape.gradient(loss, variables)\n\n    optimizer.apply_gradients(zip(gradients, variables))\n\n    return batch_loss","execution_count":49,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"EPOCHS = 10\n\nfor epoch in range(EPOCHS):\n    start = time.time()\n\n    enc_hidden = encoder.initialize_hidden_state()\n    total_loss = 0\n\n    for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n        batch_loss = train_step(inp, targ, enc_hidden)\n        total_loss += batch_loss\n\n        if batch % 10 == 0:\n            print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,batch,batch_loss.numpy()))\n\n    if (epoch + 1) % 10 == 0:\n        checkpoint.save(file_prefix = checkpoint_prefix)\n\n    print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n                                      total_loss / steps_per_epoch))\n    print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))","execution_count":52,"outputs":[{"output_type":"stream","text":"Epoch 1 Batch 0 Loss 0.4893\nEpoch 1 Batch 10 Loss 0.5146\nEpoch 1 Batch 20 Loss 0.5654\nEpoch 1 Batch 30 Loss 0.5243\nEpoch 1 Loss 0.5164\nTime taken for 1 epoch 3.1334402561187744 sec\n\nEpoch 2 Batch 0 Loss 0.4662\nEpoch 2 Batch 10 Loss 0.4633\nEpoch 2 Batch 20 Loss 0.4793\nEpoch 2 Batch 30 Loss 0.5003\nEpoch 2 Loss 0.4670\nTime taken for 1 epoch 2.9973957538604736 sec\n\nEpoch 3 Batch 0 Loss 0.3999\nEpoch 3 Batch 10 Loss 0.4517\nEpoch 3 Batch 20 Loss 0.3948\nEpoch 3 Batch 30 Loss 0.4371\nEpoch 3 Loss 0.4222\nTime taken for 1 epoch 3.111346960067749 sec\n\nEpoch 4 Batch 0 Loss 0.4089\nEpoch 4 Batch 10 Loss 0.3573\nEpoch 4 Batch 20 Loss 0.3450\nEpoch 4 Batch 30 Loss 0.3539\nEpoch 4 Loss 0.3788\nTime taken for 1 epoch 3.032662868499756 sec\n\nEpoch 5 Batch 0 Loss 0.3370\nEpoch 5 Batch 10 Loss 0.3105\nEpoch 5 Batch 20 Loss 0.3913\nEpoch 5 Batch 30 Loss 0.4204\nEpoch 5 Loss 0.3506\nTime taken for 1 epoch 3.072936534881592 sec\n\nEpoch 6 Batch 0 Loss 0.2958\nEpoch 6 Batch 10 Loss 0.3280\nEpoch 6 Batch 20 Loss 0.2927\nEpoch 6 Batch 30 Loss 0.3257\nEpoch 6 Loss 0.3197\nTime taken for 1 epoch 3.0976672172546387 sec\n\nEpoch 7 Batch 0 Loss 0.2274\nEpoch 7 Batch 10 Loss 0.2710\nEpoch 7 Batch 20 Loss 0.2823\nEpoch 7 Batch 30 Loss 0.3011\nEpoch 7 Loss 0.2920\nTime taken for 1 epoch 3.382723331451416 sec\n\nEpoch 8 Batch 0 Loss 0.2289\nEpoch 8 Batch 10 Loss 0.2435\nEpoch 8 Batch 20 Loss 0.2905\nEpoch 8 Batch 30 Loss 0.2763\nEpoch 8 Loss 0.2613\nTime taken for 1 epoch 3.0215587615966797 sec\n\nEpoch 9 Batch 0 Loss 0.2056\nEpoch 9 Batch 10 Loss 0.2423\nEpoch 9 Batch 20 Loss 0.2216\nEpoch 9 Batch 30 Loss 0.2766\nEpoch 9 Loss 0.2342\nTime taken for 1 epoch 3.0391135215759277 sec\n\nEpoch 10 Batch 0 Loss 0.1891\nEpoch 10 Batch 10 Loss 0.2199\nEpoch 10 Batch 20 Loss 0.1912\nEpoch 10 Batch 30 Loss 0.2279\nEpoch 10 Loss 0.2109\nTime taken for 1 epoch 3.291792631149292 sec\n\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# Prediction Of the Model:"},{"metadata":{"trusted":true},"cell_type":"code","source":"hin_ind_to_word={}\n\nfor i in hin_word_to_ind:\n    hin_ind_to_word[hin_word_to_ind[i]]=i\n    \nen_ind_to_word={}\n\nfor i in en_word_to_ind:\n    en_ind_to_word[en_word_to_ind[i]]=i","execution_count":53,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocess_sentence(sentence):\n    x=sentence.lower()\n    x=''.join(ch for ch in x if ch not in sc)\n    x=''.join([i for i in x if not i.isdigit()])\n    x='<start> '+x+' <end>'\n    return x","execution_count":54,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def evaluate(sentence):\n\n    sentence = preprocess_sentence(sentence)\n   \n    inputs = [en_word_to_ind[i] for i in sentence.split(' ')]\n    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs], maxlen=25,padding='post')\n    inputs = tf.convert_to_tensor(inputs)\n\n    result = ''\n\n    hidden = [tf.zeros((1, 512))]\n    enc_out, enc_hidden = encoder(inputs, hidden)\n\n    dec_hidden = enc_hidden\n    dec_input = tf.expand_dims([hin_word_to_ind['<start>']], 0)\n\n    for t in range(25):\n        predictions, dec_hidden, attention_weights = decoder(dec_input,\n                                                         dec_hidden,\n                                                         enc_out)\n        attention_weights = tf.reshape(attention_weights, (-1, ))\n        \n\n        predicted_id = tf.argmax(predictions[0]).numpy()\n\n        \n\n        if hin_ind_to_word[predicted_id] == '<end>':\n            return result, sentence\n        result += hin_ind_to_word[predicted_id] + ' '\n\n        dec_input = tf.expand_dims([predicted_id], 0)\n\n    return result, sentence","execution_count":56,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(5):\n    k=int(input())\n    sentence=''\n    for j in range(1,len(x_val[k])-1):\n        if  x_val[k][j+1]==0:\n            continue\n        sentence+=en_ind_to_word[x_val[k][j]]+' '\n    \n    pred,x=evaluate(sentence.strip())\n    actual=''\n    for j in range(1,len(y_val[k])-1):\n        if  x_val[k][j+1]==0:\n            continue\n        \n        actual+=' '+hin_ind_to_word[y_val[k][j]]\n    x=' '.join([j for j in x.split()[1:-1]])       \n    print(\"english sentence---> \"+x)\n    print('\\n')\n    print('predicted sentence--->'+pred)\n    print('\\n')\n    print('actual sentence-->'+actual)\n    print('\\n')\n    print('--------------------------------------')","execution_count":58,"outputs":[{"output_type":"stream","name":"stdout","text":"45\nenglish sentence---> i am wondering whether to take on that job\n\n\npredicted sentence--->मैं गाड़ी चला सकता हूँ। \n\n\nactual sentence--> मैं सोच रहा हूँ कि नौकरी लूँ या नहीं\n\n\n--------------------------------------\n86\nenglish sentence---> the room smelled of tobacco\n\n\npredicted sentence--->हम सब बहुत सारी बातें हैं। \n\n\nactual sentence--> कमरे में तम्बाकू की महक\n\n\n--------------------------------------\n98\nenglish sentence---> it is not raining much this year\n\n\npredicted sentence--->यह तो आज कोई नहीं है। \n\n\nactual sentence--> इस साल ज़्यादा बारिश नहीं हो रही\n\n\n--------------------------------------\n5\nenglish sentence---> he will get well soon\n\n\npredicted sentence--->वह तीन बजे से आता है। \n\n\nactual sentence--> वह जल्द ही ठीक हो\n\n\n--------------------------------------\n8\nenglish sentence---> we are anxious for world peace\n\n\npredicted sentence--->हम अच्छे से हँस पड़ी। \n\n\nactual sentence--> हम विश्व शांति के लिए तत्पर\n\n\n--------------------------------------\n"}]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}